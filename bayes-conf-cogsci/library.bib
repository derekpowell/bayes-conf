@book{Carnap1962,
author={Carnap, Rudolf},
year={1962},
title={Logical Foundations of Probability},
edition={2},
publisher={The University of Chicago Press},
address={Chicago},
}

@article{Christensen1999,
author={Christensen, David},
title={Measuring Confirmation},
journal={Journal of Philosophy},
volume={96},
issue={9},
year={1999},
pages={437-461}
}

@article{CTG2007,
author={Crupi, Vincenzo and Tentori, Katya and Gonzalez, Michel},
title={On Bayesian Measures of Evidential Support},
journal={Philosophy of Science},
volume={74},
issue={2},
year={2007},
pages={229-252}
}

@book{Earman1992,
author={Earman, John},
year={1992},
title={Bayes or Bust},
publisher={MIT Press},
address={Cambridge},
}

@article{EF2000,
author={Eells, Ellery  and Fitelson, Branden},
title={Measuring Confirmation and Evidence},
journal={The Journal of Philosophy},
volume={97},
issue={12},
year={2000},
pages={663-672}
}

@article{EF2002,
author={Eells, Ellery  and Fitelson, Branden},
title={Symmetries and Asymmetries in Evidential Support},
journal={Philosophical Studies},
volume={107},
issue={},
year={2002},
pages={129-142}
}

@article{Fitelson1999,
author={Fitelson, Branden},
title={The Plurality of Bayesian Measures of Confirmation and the Problem of Measure Sensitivity},
journal={Philosophy of Science},
volume={66},
issue={Proceedings},
year={1999},
pages={S362-S378}
}

@article{Fitelson2001,
author={Fitelson, Branden},
title={A Bayesian Account of Independent Evidence with Applications},
journal={Philosophy of Science},
volume={68},
issue={S3},
year={2001},
pages={S123-S140}
}

@article{Fitelson2021,
author={Fitelson, Branden},
title={A Problem for Confirmation Measure Z},
journal={Philosophy of Science},
volume={88},
issue={4},
year={2021},
pages={726-730}
}

@book{Glymour1980,
author={Glymour, Clark},
year={1980},
title={Theory and Evidence},
publisher={Princeton University Press},
address={Princeton}
}

@article{Good1975,
author={Good, Irving John},
title={Explicativity, Corroboration, and the Relative Odds of Hypotheses},
journal={Synthese},
volume={30},
issue={},
year={1975},
pages={39-73}
}

@book{Good1983,
author={Good, Irving John},
year={1983},
title={Good Thinking},
publisher={University of Minnesota Press},
address={Minneapolis}
}

@book{Joyce1999,
author={Joyce, James},
year={1999},
title={The Foundations of Causal Decision Theory},
publisher={Cambridge University Press},
address={Cambridge},
}

@article{Milne1996,
author={Milne, Peter},
title={\emph{log[P(h/eb)/P(h/b)]} Is the One True Measure of Confirmation},
journal={Philosophy of Science},
volume={63},
issue={1},
year={1996},
pages={21-26}
}

@article{TCBO2007,
author={Tentori, Katya and Crupi, Vincenzo and Bonini, Nicolao and Osherson, Daniel},
title={Comparision of Confirmation Measures},
journal={Cognition},
volume={103},
issue={},
year={2007},
pages={107-119}
}


@article{cook.lewandowsky2016,
	title = {Rational {Irrationality}: {Modeling} {Climate} {Change} {Belief} {Polarization} {Using} {Bayesian} {Networks}},
	volume = {8},
	issn = {17568757},
	shorttitle = {Rational {Irrationality}},
	url = {http://doi.wiley.com/10.1111/tops.12186},
	doi = {10.1111/tops.12186},
	abstract = {Belief polarization is said to occur when two people respond to the same evidence by updating their beliefs in opposite directions. This response is considered to be “irrational” because it involves contrary updating, a form of belief updating that appears to violate normatively optimal responding, as for example dictated by Bayes’ theorem. In light of much evidence that people are capable of normatively optimal behavior, belief polarization presents a puzzling exception. We show that Bayesian networks, or Bayes nets, can simulate rational belief updating. When ﬁt to experimental data, Bayes nets can help identify the factors that contribute to polarization. We present a study into belief updating concerning the reality of climate change in response to information about the scientiﬁc consensus on anthropogenic global warming (AGW). The study used representative samples of Australian and U.S. participants. Among Australians, consensus information partially neutralized the inﬂuence of worldview, with free-market supporters showing a greater increase in acceptance of human-caused global warming relative to free-market opponents. In contrast, while consensus information overall had a positive effect on perceived consensus among U.S. participants, there was a reduction in perceived consensus and acceptance of humancaused global warming for strong supporters of unregulated free markets. Fitting a Bayes net model to the data indicated that under a Bayesian framework, free-market support is a signiﬁcant driver of beliefs about climate change and trust in climate scientists. Further, active distrust of climate scientists among a small number of U.S. conservatives drives contrary updating in response to consensus information among this particular group.},
	language = {en},
	number = {1},
	urldate = {2021-03-12},
	journal = {Topics in Cognitive Science},
	author = {Cook, John and Lewandowsky, Stephan},
	month = jan,
	year = {2016},
	pages = {160--179},
	file = {Cook and Lewandowsky - 2016 - Rational Irrationality Modeling Climate Change Be.pdf:/Users/derekpowell/Zotero/storage/XJER6NIG/Cook and Lewandowsky - 2016 - Rational Irrationality Modeling Climate Change Be.pdf:application/pdf},
}

@article{jern.etal2014,
	title = {Belief polarization is not always irrational.},
	volume = {121},
	issn = {1939-1471, 0033-295X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0035941},
	doi = {10.1037/a0035941},
	abstract = {Belief polarization occurs when 2 people with opposing prior beliefs both strengthen their beliefs after observing the same data. Many authors have cited belief polarization as evidence of irrational behavior. We show, however, that some instances of polarization are consistent with a normative account of belief revision. Our analysis uses Bayesian networks to characterize different kinds of relationships between hypotheses and data, and distinguishes between cases in which normative reasoners with opposing beliefs should both strengthen their beliefs, cases in which both should weaken their beliefs, and cases in which one should strengthen and the other should weaken his or her belief. We apply our analysis to several previous studies of belief polarization and present a new experiment that suggests that people tend to update their beliefs in the directions predicted by our normative account.},
	language = {en},
	number = {2},
	urldate = {2021-03-12},
	journal = {Psychological Review},
	author = {Jern, Alan and Chang, Kai-min K. and Kemp, Charles},
	year = {2014},
	pages = {206--224},
	file = {Jern et al. - 2014 - Belief polarization is not always irrational..pdf:/Users/derekpowell/Zotero/storage/CYMC3BZF/Jern et al. - 2014 - Belief polarization is not always irrational..pdf:application/pdf},
}

@article{chater.etal2020,
	title = {Probabilistic {Biases} {Meet} the {Bayesian} {Brain}},
	volume = {29},
	issn = {0963-7214},
	url = {https://doi.org/10.1177/0963721420954801},
	doi = {10.1177/0963721420954801},
	abstract = {In Bayesian cognitive science, the mind is seen as a spectacular probabilistic-inference machine. But judgment and decision-making (JDM) researchers have spent half a century uncovering how dramatically and systematically people depart from rational norms. In this article, we outline recent research that opens up the possibility of an unexpected reconciliation. The key hypothesis is that the brain neither represents nor calculates with probabilities but approximates probabilistic calculations by drawing samples from memory or mental simulation. Sampling models diverge from perfect probabilistic calculations in ways that capture many classic JDM findings, which offers the hope of an integrated explanation of classic heuristics and biases, including availability, representativeness, and anchoring and adjustment.},
	number = {5},
	urldate = {2021-03-26},
	journal = {Current Directions in Psychological Science},
	author = {Chater, Nick and Zhu, Jian-Qiao and Spicer, Jake and Sundh, Joakim and León-Villagrá, Pablo and Sanborn, Adam},
	month = oct,
	year = {2020},
	note = {Publisher: SAGE Publications Inc},
	pages = {506--512},
	file = {chater et al-2020-probabilistic biases meet the bayesian brain.pdf:/Users/derekpowell/Zotero/storage/R6NQP5YJ/chater et al-2020-probabilistic biases meet the bayesian brain.pdf:application/pdf},
}

@article{tenenbaum.etal2011,
	title = {How to {Grow} a {Mind}: {Statistics}, {Structure}, and {Abstraction}},
	volume = {331},
	copyright = {Copyright © 2011, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	shorttitle = {How to {Grow} a {Mind}},
	url = {http://science.sciencemag.org/content/331/6022/1279},
	doi = {10.1126/science.1192788},
	abstract = {In coming to understand the world—in learning concepts, acquiring language, and grasping causal relations—our minds make inferences that appear to go far beyond the data available. How do we do it? This review describes recent approaches to reverse-engineering human learning and cognitive development and, in parallel, engineering more humanlike machine learning systems. Computational models that perform probabilistic inference over hierarchies of flexibly structured representations can address some of the deepest questions about the nature and origins of human thought: How does abstract knowledge guide learning and reasoning from sparse data? What forms does our knowledge take, across different domains and tasks? And how is that abstract knowledge itself acquired?},
	language = {en},
	number = {6022},
	urldate = {2021-06-09},
	journal = {Science},
	author = {Tenenbaum, Joshua B. and Kemp, Charles and Griffiths, Thomas L. and Goodman, Noah D.},
	month = mar,
	year = {2011},
	pmid = {21393536},
	note = {Publisher: American Association for the Advancement of Science
Section: Review},
	pages = {1279--1285},
	file = {Full Text PDF:/Users/derekpowell/Zotero/storage/BSQ6ZNW7/Tenenbaum et al. - 2011 - How to Grow a Mind Statistics, Structure, and Abs.pdf:application/pdf;Snapshot:/Users/derekpowell/Zotero/storage/E2HRQ9H6/1279.html:text/html},
}

@article{battaglia.etal2013,
	title = {Simulation as an engine of physical scene understanding},
	volume = {110},
	copyright = {©  . Freely available online through the PNAS open access option.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/110/45/18327},
	doi = {10.1073/pnas.1306572110},
	abstract = {In a glance, we can perceive whether a stack of dishes will topple, a branch will support a child’s weight, a grocery bag is poorly packed and liable to tear or crush its contents, or a tool is firmly attached to a table or free to be lifted. Such rapid physical inferences are central to how people interact with the world and with each other, yet their computational underpinnings are poorly understood. We propose a model based on an “intuitive physics engine,” a cognitive mechanism similar to computer engines that simulate rich physics in video games and graphics, but that uses approximate, probabilistic simulations to make robust and fast inferences in complex natural scenes where crucial information is unobserved. This single model fits data from five distinct psychophysical tasks, captures several illusions and biases, and explains core aspects of human mental models and common-sense reasoning that are instrumental to how humans understand their everyday world.},
	language = {en},
	number = {45},
	urldate = {2021-06-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Battaglia, Peter W. and Hamrick, Jessica B. and Tenenbaum, Joshua B.},
	month = nov,
	year = {2013},
	pmid = {24145417},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	pages = {18327--18332},
	file = {Full Text PDF:/Users/derekpowell/Zotero/storage/ILTH8F7H/Battaglia et al. - 2013 - Simulation as an engine of physical scene understa.pdf:application/pdf;Snapshot:/Users/derekpowell/Zotero/storage/MJS3HUGG/18327.html:text/html},
}

@article{gershman2019,
	title = {How to never be wrong},
	volume = {26},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/10.3758/s13423-018-1488-8},
	doi = {10.3758/s13423-018-1488-8},
	abstract = {Human beliefs have remarkable robustness in the face of disconfirmation. This robustness is often explained as the product of heuristics or motivated reasoning. However, robustness can also arise from purely rational principles when the reasoner has recourse to ad hoc auxiliary hypotheses. Auxiliary hypotheses primarily function as the linking assumptions connecting different beliefs to one another and to observational data, but they can also function as a “protective belt” that explains away disconfirmation by absorbing some of the blame. The present article traces the role of auxiliary hypotheses from philosophy of science to Bayesian models of cognition and a host of behavioral phenomena, demonstrating their wide-ranging implications.},
	language = {en},
	number = {1},
	urldate = {2021-07-10},
	journal = {Psychonomic Bulletin \& Review},
	author = {Gershman, Samuel J.},
	month = feb,
	year = {2019},
	pages = {13--28},
	file = {Gershman - 2019 - How to never be wrong.pdf:/Users/derekpowell/Zotero/storage/R8E6QHWW/Gershman - 2019 - How to never be wrong.pdf:application/pdf},
}

@article{wood.porter2019,
	title = {The {Elusive} {Backfire} {Effect}: {Mass} {Attitudes}’ {Steadfast} {Factual} {Adherence}},
	volume = {41},
	issn = {1573-6687},
	shorttitle = {The {Elusive} {Backfire} {Effect}},
	url = {https://doi.org/10.1007/s11109-018-9443-y},
	doi = {10.1007/s11109-018-9443-y},
	abstract = {Can citizens heed factual information, even when such information challenges their partisan and ideological attachments? The “backfire effect,” described by Nyhan and Reifler (Polit Behav 32(2):303–330. https://doi.org/10.1007/s11109-010-9112-2, 2010), says no: rather than simply ignoring factual information, presenting respondents with facts can compound their ignorance. In their study, conservatives presented with factual information about the absence of Weapons of Mass Destruction in Iraq became more convinced that such weapons had been found. The present paper presents results from five experiments in which we enrolled more than 10,100 subjects and tested 52 issues of potential backfire. Across all experiments, we found no corrections capable of triggering backfire, despite testing precisely the kinds of polarized issues where backfire should be expected. Evidence of factual backfire is far more tenuous than prior research suggests. By and large, citizens heed factual information, even when such information challenges their ideological commitments.},
	language = {en},
	number = {1},
	urldate = {2021-10-07},
	journal = {Political Behavior},
	author = {Wood, Thomas and Porter, Ethan},
	month = mar,
	year = {2019},
	pages = {135--163},
	file = {Wood_Porter-2019-The Elusive Backfire Effect.pdf:/Users/derekpowell/Zotero/storage/QE7GCRXG/Wood_Porter-2019-The Elusive Backfire Effect.pdf:application/pdf},
}

@incollection{hahn.harris2014,
	title = {What {Does} {It} {Mean} to be {Biased}},
	volume = {61},
	isbn = {978-0-12-800283-4},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780128002834000022},
	language = {en},
	urldate = {2021-11-03},
	booktitle = {Psychology of {Learning} and {Motivation}},
	publisher = {Elsevier},
	author = {Hahn, Ulrike and Harris, Adam J.L.},
	year = {2014},
	doi = {10.1016/B978-0-12-800283-4.00002-2},
	pages = {41--102},
	file = {Hahn and Harris - 2014 - What Does It Mean to be Biased.pdf:/Users/derekpowell/Zotero/storage/MVF8S59V/Hahn and Harris - 2014 - What Does It Mean to be Biased.pdf:application/pdf},
}

@article{sharot.etal2011,
	title = {How unrealistic optimism is maintained in the face of reality},
	volume = {14},
	issn = {1546-1726},
	url = {http://www.nature.com/articles/nn.2949},
	doi = {10.1038/nn.2949},
	abstract = {This study reports that people are worse at incorporating negative information when updating their beliefs. Correspondingly, neural activity encodes desirable information updates, but there is weaker encoding of unexpectedly undesirable information.},
	language = {en},
	number = {11},
	urldate = {2021-11-15},
	journal = {Nature Neuroscience},
	author = {Sharot, Tali and Korn, Christoph W. and Dolan, Raymond J.},
	month = nov,
	year = {2011},
	note = {Bandiera\_abtest: a
Cg\_type: Nature Research Journals
Number: 11
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Brain imaging;Decision;Learning and memory
Subject\_term\_id: brain-imaging;decision;learning-and-memory},
	keywords = {Brain imaging, Decision, Learning and memory},
	pages = {1475--1479},
	file = {Full Text:/Users/derekpowell/Zotero/storage/WR94DDL3/Sharot et al. - 2011 - How unrealistic optimism is maintained in the face.pdf:application/pdf;Snapshot:/Users/derekpowell/Zotero/storage/PMN87VBP/nn.html:text/html},
}

@inproceedings{corner.etal2010,
	title = {Conservatism in {Belief} {Revision} and {Participant} {Skepticism}},
	abstract = {Comparing the responses of participants in reasoning experiments to the normative standard of Bayes’ Theorem has been a popular empirical approach for almost half a century. One longstanding finding is that people’s belief revision is conservative with respect to the normative prescriptions of Bayes’ Theorem, that is, beliefs are revised less than they should be. In this paper, we consider a novel explanation of conservatism, namely that participants do not perceive information provided to them in experiments as coming from a fully reliable source. From the Bayesian perspective, less reliable evidence should lead to more conservative belief revision. Thus, there may be less of discrepancy between normative predictions and behavioural data than previously assumed.},
	language = {en},
	booktitle = {Proceedings of the 32nd {Annual} {Conference} of the {Cognitive} {Science} {Society}},
	author = {Corner, Adam and Harris, Adam J. L. and Hahn, Ulrike},
	year = {2010},
	pages = {6},
	file = {Corner - Conservatism in Belief Revision and Participant Sk.pdf:/Users/derekpowell/Zotero/storage/HBHRY86K/cornerEtAl2010.pdf:application/pdf},
}

@incollection{edwards1968,
	address = {New York},
	title = {Conservatism in {Human} {Information} {Processing}},
	booktitle = {Formal representation of human judgment},
	publisher = {Wiley},
	author = {Edwards, Ward},
	editor = {Kleinmuntz, B.},
	year = {1968},
	pages = {17--52},
}

@article{yang.etal,
	title = {Asymmetry in {Belief} {Revision}},
	volume = {n/a},
	issn = {1099-0720},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/acp.3991},
	doi = {10.1002/acp.3991},
	abstract = {Information changes: science advances, newspapers retract claims, and recommendations shift. Successfully navigating the world requires updating and changing beliefs, a process that is sensitive to a person’s motivation to change their beliefs as well as the credibility of the source providing the new information. Here, we report three studies that consistently identify an additional factor influencing belief revision. Specifically, we document an asymmetry in belief revision: people are better able to believe in a claim once thought to be false, as opposed to unbelieving something once believed to be true. We discuss how this finding integrates and extends prior research on social and cognitive contributions to belief revisions. This work has implications for understanding the widespread prevalence and persistence of false beliefs in contemporary societies. This article is protected by copyright. All rights reserved.},
	language = {en},
	number = {n/a},
	urldate = {2022-09-02},
	journal = {Applied Cognitive Psychology},
	author = {Yang, Brenda W. and Stone, Alexandria R. and Marsh, Elizabeth J.},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/acp.3991},
	keywords = {misinformation, belief revision, feedback, negation, truth},
	file = {Snapshot:/Users/derekpowell/Zotero/storage/76WR7HMF/acp.html:text/html;yang et al-asymmetry in belief revision.pdf:/Users/derekpowell/Documents/Papers/yang et al-asymmetry in belief revision.pdf:application/pdf},
}

@inproceedings{powell2022,
	title = {A descriptive bayesian account of optimism in belief revision},
	booktitle = {Proceedings of the 42nd {Annual} {Conference} of the {Cognitive} {Science} {Society}},
	author = {Powell, Derek},
	editor = {Jennifer, Culbertson and Perfors, Andrew and Rabagliati, Hugh and Ramenzoni, Veronica},
	year = {2022},
}

@inproceedings{schotsch.powell2022,
	address = {Austin, TX},
	title = {Understanding intuitive theories of climate change},
	abstract = {There is a pressing need to inform the public and drive personal and political action to mitigate climate change. Recent theorizing suggests that people’s intuitive theories may be key levers for affecting attitude and behavior change (Weisman \& Markman, 2017). We asked 400 participants to estimate the probability of different future events related to climate change. Our findings indicate that people hold coherent theories of climate change, that these theories were predictive of policy positions, and that they varied across individuals and across partisan groups. In particular, political independents and Republicans’s causal models underestimated the impacts of climate change. We also examined an educational intervention that explains a key mechanism of climate change (Ranney \& Clark, 2016). Unfortunately, while the intervention increased mechanistic knowledge, it did not affect participants’ beliefs about climate outcomes. Nevertheless, the coherence of participants’ intuitive theories gives hope that other educational interventions could have meaningful and systematic effects on policy attitudes and political behaviors.},
	language = {en},
	booktitle = {Proceedings of the 44th {Annual} {Meeting} of the {Cognitive} {Science} {Society}},
	publisher = {Cognitive Science Society},
	author = {Schotsch, Brittany and Powell, Derek},
	editor = {Culbertson, J and Perfors, A and Rabagliati, H and Ramenzoni, V},
	year = {2022},
	file = {Schotsch and Powell - Understanding intuitive theories of climate change.pdf:/Users/derekpowell/Zotero/storage/46UAMPZP/Schotsch and Powell - Understanding intuitive theories of climate change.pdf:application/pdf},
}

@article{crupi.etal2008,
	title = {Probability, confirmation, and the conjunction fallacy},
	volume = {14},
	issn = {1354-6783, 1464-0708},
	url = {http://www.tandfonline.com/doi/abs/10.1080/13546780701643406},
	doi = {10.1080/13546780701643406},
	language = {en},
	number = {2},
	urldate = {2023-01-25},
	journal = {Thinking \& Reasoning},
	author = {Crupi, Vincenzo and Fitelson, Branden and Tentori, Katya},
	month = may,
	year = {2008},
	pages = {182--199},
	file = {Crupi et al. - 2008 - Probability, confirmation, and the conjunction fal.pdf:/Users/derekpowell/Zotero/storage/53Y8DNQI/Crupi et al. - 2008 - Probability, confirmation, and the conjunction fal.pdf:application/pdf},
}

@article{tentori.etal2016,
	title = {Judging the {Probability} of {Hypotheses} {Versus} the {Impact} of {Evidence}: {Which} {Form} of {Inductive} {Inference} {Is} {More} {Accurate} and {Time}-{Consistent}?},
	volume = {40},
	issn = {03640213},
	shorttitle = {Judging the {Probability} of {Hypotheses} {Versus} the {Impact} of {Evidence}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/cogs.12259},
	doi = {10.1111/cogs.12259},
	abstract = {Inductive reasoning requires exploiting links between evidence and hypotheses. This can be done focusing either on the posterior probability of the hypothesis when updated on the new evidence or on the impact of the new evidence on the credibility of the hypothesis. But are these two cognitive representations equally reliable? This study investigates this question by comparing probability and impact judgments on the same experimental materials. The results indicate that impact judgments are more consistent in time and more accurate than probability judgments. Impact judgments also predict the direction of errors in probability judgments. These ﬁndings suggest that human inductive reasoning relies more on estimating evidential impact than on posterior probability.},
	language = {en},
	number = {3},
	urldate = {2023-01-25},
	journal = {Cognitive Science},
	author = {Tentori, Katya and Chater, Nick and Crupi, Vincenzo},
	month = apr,
	year = {2016},
	pages = {758--778},
	file = {Tentori et al. - 2016 - Judging the Probability of Hypotheses Versus the I.pdf:/Users/derekpowell/Zotero/storage/MVKAS37A/Tentori et al. - 2016 - Judging the Probability of Hypotheses Versus the I.pdf:application/pdf},
}

@article{mobius.etal2022,
	title = {Managing {Self}-{Confidence}: {Theory} and {Experimental} {Evidence}},
	volume = {68},
	issn = {0025-1909},
	shorttitle = {Managing {Self}-{Confidence}},
	url = {https://pubsonline.informs.org/doi/full/10.1287/mnsc.2021.4294},
	doi = {10.1287/mnsc.2021.4294},
	abstract = {We use a series of experiments to understand whether and how people’s beliefs about their own abilities are biased relative to the Bayesian benchmark and how these beliefs then affect behavior. We find that subjects systematically and substantially overweight positive feedback relative to negative (asymmetry) and also update too little overall (conservatism). These biases are substantially less pronounced in an ego-free control experiment. Updating does retain enough of the structure of Bayes’ rule to let us model it coherently in an optimizing framework, in which, interestingly, asymmetry and conservatism emerge as complementary biases. We also find that exogenous changes in beliefs affect subjects’ decisions to enter into a competition and do so similarly for more and less biased subjects, suggesting that people cannot “undo” their biases when the time comes to decide.

This paper was accepted by Axel Ockenfels, behavioral economics and decision analysis.

Funding: Financial support from the National Science Foundation (NSF), Harvard University, and Wesleyan University is gratefully acknowledged. P. Niehaus received financial support from an NSF Graduate Research Fellowship.

Supplemental Material: The data files are available at https://doi.org/10.1287/mnsc.2021.4294.},
	number = {11},
	urldate = {2023-01-26},
	journal = {Management Science},
	author = {Möbius, Markus M. and Niederle, Muriel and Niehaus, Paul and Rosenblat, Tanya S.},
	month = nov,
	year = {2022},
	note = {Publisher: INFORMS},
	keywords = {asymmetric belief updating, conservatism, information aversion, overconfidence},
	pages = {7793--7817},
	file = {möbius et al-2022-managing self-confidence.pdf:/Users/derekpowell/Documents/Papers/möbius et al-2022-managing self-confidence.pdf:application/pdf},
}

@article{barron2021,
	title = {Belief updating: does the ‘good-news, bad-news’ asymmetry extend to purely financial domains?},
	volume = {24},
	issn = {1573-6938},
	shorttitle = {Belief updating},
	url = {https://doi.org/10.1007/s10683-020-09653-z},
	doi = {10.1007/s10683-020-09653-z},
	abstract = {Bayes’ statistical rule remains the status quo for modeling belief updating in both normative and descriptive models of behavior under uncertainty. Some recent research has questioned the use of Bayes’ rule in descriptive models of behavior, presenting evidence that people overweight ‘good news’ relative to ‘bad news’ when updating ego-relevant beliefs. In this paper, we present experimental evidence testing whether this ‘good-news, bad-news’ effect is present in a financial decision making context (i.e. a domain that is important for understanding much economic decision making). We find no evidence of asymmetric updating in this domain. In contrast, in our experiment, belief updating is close to the Bayesian benchmark on average. However, we show that this average behavior masks substantial heterogeneity in individual updating behavior. We find no evidence in support of a sizeable subgroup of asymmetric updators.},
	language = {en},
	number = {1},
	urldate = {2023-01-26},
	journal = {Experimental Economics},
	author = {Barron, Kai},
	month = mar,
	year = {2021},
	pages = {31--58},
	file = {barron-2021-belief updating.pdf:/Users/derekpowell/Documents/Papers/barron-2021-belief updating.pdf:application/pdf},
}

@article{nelson2005,
	title = {Finding {Useful} {Questions}: {On} {Bayesian} {Diagnosticity}, {Probability}, {Impact}, and {Information} {Gain}},
	volume = {112},
	copyright = {© 2005, American Psychological Association},
	issn = {0033-295X},
	shorttitle = {Finding {Useful} {Questions}},
	url = {https://www.proquest.com/docview/614432463/abstract/CD8C5433237046C2PQ/1},
	doi = {10.1037/0033-295X.112.4.979},
	abstract = {[Correction Notice: An erratum for this article was reported in Vol 114(3) of Psychological Review (see record 2007-10421-013). In Table 13, the data should indicate that 7\% of females had short hair and 93\% of females had long hair. The calculations and discussion in the article were based on these correct percentages.] Several norms for how people should assess a question's usefulness have been proposed, notably Bayesian diagnosticity, information gain (mutual information), Kullback-Liebler distance, probability gain (error minimization), and impact (absolute change). Several probabilistic models of previous experiments on categorization, covariation assessment, medical diagnosis, and the selection task are shown to not discriminate among these norms as descriptive models of human intuitions and behavior. Computational optimization found situations in which information gain, probability gain, and impact strongly contradict Bayesian diagnosticity. In these situations, diagnosticity's claims are normatively inferior. Results of a new experiment strongly contradict the predictions of Bayesian diagnosticity. Normative theoretical concerns also argue against use of diagnosticity. It is concluded that Bayesian diagnosticity is normatively flawed and empirically unjustified. (PsycINFO Database Record (c) 2016 APA, all rights reserved) (Source: journal abstract)},
	language = {English},
	number = {4},
	urldate = {2023-01-26},
	journal = {Psychological Review},
	author = {Nelson, Jonathan D.},
	month = oct,
	year = {2005},
	note = {Num Pages: 979-999
Place: Washington, US
Publisher: American Psychological Association
(US)},
	keywords = {Decision Theory (major), Diagnosis, Experimental Design, Information (major), Questioning (major), Statistical Probability (major)},
	pages = {979--999},
	file = {nelson-2005-finding useful questions.pdf:/Users/derekpowell/Documents/Papers/nelson-2005-finding useful questions.pdf:application/pdf},
}

@article{tentori.etal2007,
	title = {Comparison of confirmation measures},
	volume = {103},
	issn = {00100277},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027706000631},
	doi = {10.1016/j.cognition.2005.09.006},
	abstract = {Alternative measures of conﬁrmation or evidential support have been proposed to express the impact of ascertaining one event on the credibility of another. We report an experiment that compares the adequacy of several such measures as descriptions of conﬁrmation judgment in a probabilistic context.},
	language = {en},
	number = {1},
	urldate = {2023-01-26},
	journal = {Cognition},
	author = {Tentori, Katya and Crupi, Vincenzo and Bonini, Nicolao and Osherson, Daniel},
	month = apr,
	year = {2007},
	pages = {107--119},
	file = {Tentori et al. - 2007 - Comparison of confirmation measures.pdf:/Users/derekpowell/Zotero/storage/D74S9UPM/Tentori et al. - 2007 - Comparison of confirmation measures.pdf:application/pdf},
}

@article{crupi.etal2007,
	title = {On {Bayesian} {Measures} of {Evidential} {Support}: {Theoretical} and {Empirical} {Issues}},
	volume = {74},
	issn = {0031-8248, 1539-767X},
	shorttitle = {On {Bayesian} {Measures} of {Evidential} {Support}},
	url = {https://www.cambridge.org/core/product/identifier/S0031824800005110/type/journal_article},
	doi = {10.1086/520779},
	abstract = {Epistemologists and philosophers of science have often attempted to express formally the impact of a piece of evidence on the credibility of a hypothesis. In this paper we will focus on the Bayesian approach to evidential support. We will propose a new formal treatment of the notion of degree of confirmation and we will argue that it overcomes some limitations of the currently available approaches on two grounds: (i) a theoretical analysis of the confirmation relation seen as an extension of logical deduction and (ii) an empirical comparison of competing measures in an experimental inquiry concerning inductive reasoning in a probabilistic setting.},
	language = {en},
	number = {2},
	urldate = {2023-01-31},
	journal = {Philosophy of Science},
	author = {Crupi, Vincenzo and Tentori, Katya and Gonzalez, Michel},
	month = apr,
	year = {2007},
	pages = {229--252},
	file = {Crupi et al. - 2007 - On Bayesian Measures of Evidential Support Theore.pdf:/Users/derekpowell/Zotero/storage/EM7ZLF7M/Crupi et al. - 2007 - On Bayesian Measures of Evidential Support Theore.pdf:application/pdf},
}

@article{powell.etal2023,
	title = {Modeling and leveraging intuitive theories to improve vaccine attitudes},
	journal = {Journal of Experimental Psychology: General},
	author = {Powell, Derek and Weisman, Kara and Markman, Ellen M},
	year = {2023},
}
